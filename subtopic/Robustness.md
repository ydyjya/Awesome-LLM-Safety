# Robustness

## Different from the main READMEüïµÔ∏è

- Within this subtopic, we will be updating with the latest articles. This will help researchers in this area to quickly understand recent trends.
- In addition to providing the most recent updates, we will also add keywords to each subtopic to help you find content of interest more quickly.
- Within each subtopic, we will also update with profiles of scholars we admire and endorse in the field. Their work is often of high quality and forward-looking!"

## üìëPapers

| Date  |                                        Institute                                        |                                     Publication                                     |                                                                                       Paper                                                                                       |                                      Keywords                                      |
|:-----:|:---------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| 23.02 |                                   Microsoft Research                                    | ICLR 2023(workshop on Trustworthy and Reliable Large-Scale Machine Learning Models) |                               [On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective](https://arxiv.org/abs/2302.12095)                                | **Robustness Evaluation**&**Adversarial Robustness**&**Out-of-Distribution (OOD)** |
| 23.06 |                       University of Illinois at Urbana-Champaign                        |                                        arxiv                                        |                                  [DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models](https://arxiv.org/abs/2306.11698)                                   |                 **Robustness**&**Ethics**&**Privacy**&**Toxicity**                 |
| 23.08 |          CISPA Helmholtz Center for Information Security & Tsinghua University          |                                        arxiv                                        |           [Robustness Over Time: Understanding Adversarial Examples‚Äô Effectiveness on Longitudinal Versions of Large Language Models](https://arxiv.org/abs/2308.07847)           |                  **Longitudinal Study**&**Robustness Assessment**                  |
| 23.11 |                                           CMU                                           |                          AACL2023(ART or Safety workshop)                           |                                                        [Measuring Adversarial Datasets](https://arxiv.org/abs/2311.03566)                                                         |         **Adversarial Robustness**&**AI Safety**&**Adversarial Datasets**          |
| 23.11 |                                   Amazon Alexa AI-NU                                    |                                        arXiv                                        |                                           [JAB: Joint Adversarial Prompting and Belief Augmentation](https://arxiv.org/abs/2311.09473)                                            |          **Adversarial Prompting**&T**oxicity Reduction**&**Robustness**           |
| 24.01 |          University of Trento, Concordia University, Mila-Quebec AI Institute           |                                        arxiv                                        |                                                     [Are LLMs Robust for Spoken Dialogues?](https://arxiv.org/abs/2401.02297)                                                     |  **Task-Oriented Dialogues**&**Automatic Speech Recognition**&**Error Analysis**   |
| 24.01 |                    School of Computer Science University of Windsor                     |                                        arxiv                                        | [Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion](https://arxiv.org/abs/2401.11373) |    **Adversarial Attacks**&**Targeted Paraphrasing**&**Reinforcement Learning**    |
| 24.02 |                                 University of Cambridge                                 |                                        arxiv                                        |                       [Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment](https://arxiv.org/abs/2402.14016)                       |                **LLM as a Judge**&**Universal Adversarial Attacks**                |
| 24.02 |                             Technical University of Munich                              |                                        arxiv                                        | [Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images](https://arxiv.org/abs/2402.14899) | **Multimodal Large Language Models**&**Chain-of-Thought Reasoning**&**Adversarial Images** |
| 24.03 | Beijing Institute of Technology, The University of Sydney, Hong Kong Baptist University |                                        arxiv                                        | [Few-Shot Adversarial Prompt Learning on Vision-Language Models](https://arxiv.org/abs/2403.14774) | **Few-Shot Learning**&**Adversarial Prompt**&**Vision-Language Models** |
| 24.04 | University of Chinese Academy of Sciences, Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences |                                     COLING 2024                                     | [Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack](https://arxiv.org/abs/2404.01907) | **Adversarial Attack**&**AI-Text Detection**&**Dynamic Adversarial Learning** |



## üíªPresentations & Talks


## üìñTutorials & Workshops

| Date  |   Type    |       Title        |                         URL                          |
|:-----:|:---------:|:------------------:|:----------------------------------------------------:|
| 23.10 | Tutorials | Awesome-LLM-Safety | [link](https://github.com/ydyjya/Awesome-LLM-Safety) |

## üì∞News & Articles

## üßë‚Äçüè´Scholars