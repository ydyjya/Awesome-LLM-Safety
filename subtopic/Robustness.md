# Robustness

## Different from the main READMEüïµÔ∏è

- Within this subtopic, we will be updating with the latest articles. This will help researchers in this area to quickly understand recent trends.
- In addition to providing the most recent updates, we will also add keywords to each subtopic to help you find content of interest more quickly.
- Within each subtopic, we will also update with profiles of scholars we admire and endorse in the field. Their work is often of high quality and forward-looking!"

## üìëPapers

| Date  |                                                                Institute                                                                 |                                     Publication                                     |                                                                                       Paper                                                                                       |                                          Keywords                                          |
|:-----:|:----------------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------:|
| 23.02 |                                                            Microsoft Research                                                            | ICLR 2023(workshop on Trustworthy and Reliable Large-Scale Machine Learning Models) |                               [On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective](https://arxiv.org/abs/2302.12095)                                |     **Robustness Evaluation**&**Adversarial Robustness**&**Out-of-Distribution (OOD)**     |
| 23.06 |                                                University of Illinois at Urbana-Champaign                                                |                                        arxiv                                        |                                  [DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models](https://arxiv.org/abs/2306.11698)                                   |                     **Robustness**&**Ethics**&**Privacy**&**Toxicity**                     |
| 23.08 |                                  CISPA Helmholtz Center for Information Security & Tsinghua University                                   |                                        arxiv                                        |           [Robustness Over Time: Understanding Adversarial Examples‚Äô Effectiveness on Longitudinal Versions of Large Language Models](https://arxiv.org/abs/2308.07847)           |                      **Longitudinal Study**&**Robustness Assessment**                      |
| 23.11 |                                                                   CMU                                                                    |                          AACL2023(ART or Safety workshop)                           |                                                        [Measuring Adversarial Datasets](https://arxiv.org/abs/2311.03566)                                                         |             **Adversarial Robustness**&**AI Safety**&**Adversarial Datasets**              |
| 23.11 |                                                            Amazon Alexa AI-NU                                                            |                                        arXiv                                        |                                           [JAB: Joint Adversarial Prompting and Belief Augmentation](https://arxiv.org/abs/2311.09473)                                            |              **Adversarial Prompting**&T**oxicity Reduction**&**Robustness**               |
| 24.01 |                                   University of Trento, Concordia University, Mila-Quebec AI Institute                                   |                                        arxiv                                        |                                                     [Are LLMs Robust for Spoken Dialogues?](https://arxiv.org/abs/2401.02297)                                                     |      **Task-Oriented Dialogues**&**Automatic Speech Recognition**&**Error Analysis**       |
| 24.01 |                                             School of Computer Science University of Windsor                                             |                                        arxiv                                        | [Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion](https://arxiv.org/abs/2401.11373) |        **Adversarial Attacks**&**Targeted Paraphrasing**&**Reinforcement Learning**        |
| 24.02 |                                                         University of Cambridge                                                          |                                        arxiv                                        |                       [Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment](https://arxiv.org/abs/2402.14016)                       |                    **LLM as a Judge**&**Universal Adversarial Attacks**                    |
| 24.02 |                                                      Technical University of Munich                                                      |                                        arxiv                                        |                         [Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images](https://arxiv.org/abs/2402.14899)                         | **Multimodal Large Language Models**&**Chain-of-Thought Reasoning**&**Adversarial Images** |
| 24.03 |                         Beijing Institute of Technology, The University of Sydney, Hong Kong Baptist University                          |                                        arxiv                                        |                                        [Few-Shot Adversarial Prompt Learning on Vision-Language Models](https://arxiv.org/abs/2403.14774)                                         |          **Few-Shot Learning**&**Adversarial Prompt**&**Vision-Language Models**           |
| 24.04 | University of Chinese Academy of Sciences, Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences |                                     COLING 2024                                     |                          [Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack](https://arxiv.org/abs/2404.01907)                           |       **Adversarial Attack**&**AI-Text Detection**&**Dynamic Adversarial Learning**        |
| 24.04 |                  Institute for Intelligent Computing, Alibaba Group; School of Information Management, Wuhan University                  |                                        arxiv                                        |                           [Enhance Robustness of Language Models Against Variation Attack through Graph Integration](https://arxiv.org/abs/2404.12014)                            |                    **Chinese Adversarial Attacks**&**Variation Graph**                     |



## üíªPresentations & Talks


## üìñTutorials & Workshops

| Date  |   Type    |       Title        |                         URL                          |
|:-----:|:---------:|:------------------:|:----------------------------------------------------:|
| 23.10 | Tutorials | Awesome-LLM-Safety | [link](https://github.com/ydyjya/Awesome-LLM-Safety) |

## üì∞News & Articles

## üßë‚Äçüè´Scholars