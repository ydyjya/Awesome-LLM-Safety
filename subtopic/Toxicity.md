# Toxicity

## Different from the main READMEüïµÔ∏è

- Within this subtopic, we will be updating witha the latest articles. This will help researchers in this area to quickly understand recent trends.
- In addition to providing the most recent updates, we will also add keywords to each subtopic to help you find content of interest more quickly.
- Within each subtopic, we will also update with profiles of scholars we admire and endorse in the field. Their work is often of high quality and forward-looking!"


## üìëPapers

| Date  |                                                                                         Institute                                                                                          |          Publication           |                                                                                                                       Paper                                                                                                                        |                                                                 Keywords                                                                 |
|:-----:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------:|
| 20.10 |                                                                                    Facebook AI Research                                                                                    |             arxiv              |                                                                                   [Recipes for Safety in Open-domain Chatbots](https://arxiv.org/abs/2010.07079)                                                                                   |                                                    **Toxic Behavior**&**Open-domain**                                                    |
| 22.11 |                                                                            University of California, Santa Cruz                                                                            |           NAACL2024            |                                                         [Navigation as Attackers Wish? Towards Building Robust Embodied Agents under Federated Learning](https://arxiv.org/abs/2211.14769)                                                         |                                  **Federated Learning**&**Vision-and-Language Navigation**&**Security**                                  |
| 23.05 |                                                                Harvard&UCLA&USC&University of Wisconsin, Madison&UC, Davis                                                                 |           NAACL2024            |                                                      [Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models](https://arxiv.org/abs/2305.14710)                                                       |                                  **Instruction Tuning**&**Large Language Models**&**Backdoor Attacks**                                   |
| 23.06 |                                                                         University of Illinois at Urbana-Champaign                                                                         |             arxiv              |                                                                   [DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models](https://arxiv.org/abs/2306.11698)                                                                   |                                            **Robustness**&**Ethics**&**Privacy**&**Toxicity**                                            |
| 23.10 |                                                                      CISPA Helmholtz Center for Information Security                                                                       |      NAACL2024(findings)       |                                                                            [Composite Backdoor Attacks Against Large Language Models](https://arxiv.org/abs/2310.07676)                                                                            |                                       **Backdoor Attacks**&**Large Language Models**&**Security**                                        |
| 23.11 |                                                                               Pennsylvania State University                                                                                |             arxiv              |                                           [A Taxonomy of Rater Disagreements: Surveying Challenges & Opportunities from the Perspective of Annotating Online Toxicity](https://arxiv.org/abs/2311.04345)                                           |                                                         **Toxicity**&**Survey**                                                          |
| 23.11 |                                                                          University of Maryland, Baltimore County                                                                          |             arxiv              |                                                      [Determination of toxic comments and unintended model bias minimization using Deep learning approach](https://arxiv.org/abs/2311.04789)                                                       |                                                   **Toxicity**&**Detection**&**Bias**                                                    |
| 23.11 |                                                                               University of Central Florida                                                                                |             arxiv              |                                                                        [THOS: A Benchmark Dataset for Targeted Hate and Offensive Speech](https://arxiv.org/abs/2311.06446)                                                                        |                                             **Hate Speech**&**Offensive Speech**&**Dataset**                                             |
| 23.11 |                                                                                         FAIR Meta                                                                                          |             arXiv              |                                                       [Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual Translation](https://arxiv.org/abs/2311.06532)                                                        |                             **Multimodal Translation**&**Multilingual Translation**&**Toxicity Mitigation**                              |
| 23.11 |                                                                University of Haifa, OriginAI, Braude College of Engineering                                                                |             arXiv              |                                                                        [Generative AI for Hate Speech Detection: Evaluation and Findings](https://arxiv.org/abs/2311.09993)                                                                        |                                   **Hate Speech Detection**&**Synthetic Data**&&**Data Augmentation**                                    |
| 23.11 |                                             Seoul National University, Chung-Ang University, NAVER AI Lab, NAVER Cloud, University of Richmond                                             |             arxiv              |                                                                              [LifeTox: Unveiling Implicit Toxicity in Life Advice](https://arxiv.org/abs/2311.09585)                                                                               |                                   **LifeTox Dataset**&**Toxicity Detection**&**Social Media Analysis**                                   |
| 23.11 |                                                                                     Amazon Alexa AI-NU                                                                                     |             arXiv              |                                                                            [JAB: Joint Adversarial Prompting and Belief Augmentation](https://arxiv.org/abs/2311.09473)                                                                            |                                     **Adversarial Prompting**&T**oxicity Reduction**&**Robustness**                                      |
| 23.11 |                                                                      CISPA Helmholtz Center for Information Security                                                                       |             arxiv              |                                                                                [Comprehensive Assessment of Toxicity in ChatGPT](https://arxiv.org/abs/2311.14685)                                                                                 |                                         **Toxicity Assessment**&**Instruction-tuning Datasets**                                          |
| 23.11 |                                                                          Tsinghua University, TAL Education Group                                                                          |             arxiv              |                                                                            [Unveiling the Implicit Toxicity in Large Language Models](https://arxiv.org/abs/2311.17391)                                                                            |                                 **Implicit Toxicity**&**Toxicity Detection**&**Reinforcement Learning**                                  |
| 23.11 |                                                                                            Meta                                                                                            |           EMNLP2023            |                                                                       [ROBBIE: Robust Bias Evaluation of Large Generative Language Models](https://arxiv.org/abs/2311.18140)                                                                       |                                              **Bias Evaluation**&**Fairness**&**Toxicity**                                               |
| 23.12 |                                                                                         Anthropic                                                                                          |             arxiv              |                                                                      [Evaluating and Mitigating Discrimination in Language Model Decisions](https://arxiv.org/abs/2312.03689)                                                                      |                                   **Discrimination**&**High-Stakes Decisions**&**Societal Decisions**                                    |
| 23.12 |                                                                                      Ajou University                                                                                       |             arXiv              |                                                                         [GTA: Gated Toxicity Avoidance for LM Performance Preservation](https://arxiv.org/abs/2312.06122)                                                                          |                           **Toxicity Avoidance**&**Gated Toxicity Avoidance**&**Controllable Text Generation**                           |
| 23.12 |                                                      Hong Kong Baptist University; The Hong Kong University of Science and Technology                                                      |             arXiv              |                                                  [Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models](https://arxiv.org/abs/2312.05434)                                                   |                                                   **Harmful**&**Multimodal Reasoning**                                                   |
| 23.12 |                                                                     University of Southern California, Amazon.com Inc.                                                                     |             arxiv              |                                                            [Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models](https://arxiv.org/abs/2312.08303)                                                             |                                **Toxic Content Detection**&**Bootstrapping**&**Decision-Tree-of-Thought**                                |
| 23.12 |                                                       University of Texas at San Antonio, University at Buffalo, Clemson University                                                        |            S&P2024             |                                                          [Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/abs/2312.15099)                                                          |                                              **Online Hate**&**Chain-of-Thought Reasoning**                                              |
| 23.12 |                                     University of Central Florida, Samsung Research America, University of Pittsburgh, Indiana University Bloomington                                      |           NAACL2024            |                                                                              [TrojFSP: Trojan Insertion in Few-shot Prompt Tuning](https://arxiv.org/abs/2312.10467)                                                                               |                                       **Prompt Tuning**&**Backdoor Attacks**&**Few-shot Learning**                                       |
| 23.12 |                                                                             The Pennsylvania State University                                                                              |           NAACL2024            |                                                              [Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections](https://arxiv.org/abs/2312.00027)                                                              |                                   **Backdoor Injections**&**LLM Security**&**Persistent Unalignment**                                    |
| 24.01 |                                                         University of Michigan Ann Arbor, Harvard University, University of Sydney                                                         |             arxiv              |                                                             [A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity](https://arxiv.org/abs/2401.01967)                                                              |                              **Alignment Algorithms**&**Toxicity**&**Direct Preference Optimization (DPO)**                              |
| 24.01 |                                                                Algorix Convergence Research Office, Centennial High School                                                                 |             arxiv              |                                                               [EFFICACY OF UTILIZING LARGE LANGUAGE MODELS TO DETECT PUBLIC THREAT POSTED ONLINE](https://arxiv.org/abs/2401.02974)                                                                |                                                 **Content Moderation**&**Public Threat**                                                 |
| 24.01 |                    University at Buffalo, University of Texas at San Antonio, Union County Magnet High School, East Chapel Hill High School, Minhang Crosspoint Academy                    |           ICMLA2023            |                                                                 [An Investigation of Large Language Models for Real-World Hate Speech Detection](https://arxiv.org/abs/2401.03346)                                                                 |                                       **Hate Speech**&**Prompt Engineering**&**Few-shot Learning**                                       |
| 24.01 |                                                                    IRLab CITIC Research Centre, Universidade da Coru√±a                                                                     |             arxiv              |                                                                       [MetaHate: A Dataset for Unifying Efforts on Hate Speech Detection](https://arxiv.org/abs/2401.06526)                                                                        |                                                **Hate Speech Detection**&**Social Media**                                                |
| 24.02 |                                                                               University of Brighton, Ofgem                                                                                |             arxiv              |                                                                         [The Use of a Large Language Model for Cyberbullying Detection](https://arxiv.org/abs/2402.04088)                                                                          |                                                **Cyberbullying&**Social Media Analytics**                                                |
| 24.02 |                                                                                 Seoul National University                                                                                  |             arxiv              |                                                       [Can LLMs Recognize Toxicity? Structured Toxicity Investigation Framework and Semantic-Based Metric](https://arxiv.org/abs/2402.06900)                                                       |                                              **Toxicity Detection**&**Semantic Evaluation**                                              |
| 24.02 |                                                               University of Pisa&University of Edinburgh&Bocconi University                                                                |             arxiv              |                                                                           [FAIRBELIEF ‚Äì Assessing Harmful Beliefs in Language Models](https://arxiv.org/abs/2402.17389)                                                                            |                                                   **Beliefs Assessment**&**Fairness**                                                    |
| 24.02 |                                                                              Nanyang Technological University                                                                              |      NAACL2024(findings)       |                                                            [Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2402.12168)                                                             |                                          **Backdoor Attacks**&**Fine-Tuning**&**NLP Security**                                           |
| 24.03 |                             Indian Institute of Technology (IIT) Jodhpur, Indraprastha Institute of Information Technology Delhi (IIIT-D), IBM Research India                              | demonstration track of AAAI-24 |                                                                                 [LLMGuard: Guarding against Unsafe LLM Behavior](https://arxiv.org/abs/2403.00826)                                                                                 |                                              **Safety**&**Content Flagging**&**Detectors**                                               |
| 24.03 |                                                                                       Cohere for AI                                                                                        |             arxiv              |                                                                [From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models](https://arxiv.org/abs/2403.03893)                                                                 |                       **Multilingual Toxicity Mitigation**&**Translated Data**&**Retrieval-Augmented Techniques**                        |
| 24.03 |                                                                                  Arizona State University                                                                                  |             arxiv              |                             [Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection](https://arxiv.org/abs/2403.08035)                             |                                            **Hate Speech Detection**&**Text Classification**                                             |
| 24.03 |                                                           McGill University, University of Montreal, Mila - Quebec AI Institute                                                            |             arxiv              |                                                       [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](https://arxiv.org/abs/2403.13213)                                                       |                                                    **Safety**&**Biases**&**Toxicity**                                                    |
| 24.03 |     Zhejiang University, Zhejiang University-Ant Group Joint Laboratory of Knowledge Graph, Ant Group, National University of Singapore, Westlake University, Microsoft Research Asia      |             arxiv              |                                                                            [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472)                                                                             |                                       **Knowledge Editing**&**Toxicity Mitigation**&**Benchmark**                                        |
| 24.03 |                                                            University of North Texas, Peking University, University of Arizona                                                             |             arxiv              |                                                                      [Outcome-Constrained Large Language Models for Countering Hate Speech](https://arxiv.org/abs/2403.17146)                                                                      |                                                    **Counterspeech**&**Hate Speech**                                                     |
| 24.03 | The World Bank, University of Oxford, New York University, Universidade Federal de Goi√°s, Ecole Normale Sup√©rieure, Universiti Sultan Zainal Abidin, Massachusetts Institute of Technology |             arxiv              |                                                           [NAIJAHATE: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data](https://arxiv.org/abs/2403.19260)                                                            |                                  **Hate Speech Detection**&**Nigerian Twitter**&**Representative Data**                                  |
| 24.05 |                                                                                 Carnegie Mellon University                                                                                 |             arxiv              |                                                     [PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models](https://arxiv.org/abs/2405.09373)                                                      |                                                 **Multilingual Evaluation**&**Datasets*                                                  |
| 24.05 |                                                                                  Johns Hopkins University                                                                                  |      NAACL2024(findings)       | [MICo: Preventative Detoxification of Large Language Models through Inhibition Control](https://assets.amazon.science/e7/94/facc166449eba31223cbc88614a9/mico-preventative-detoxification-of-large-language-models-through-inhibition-control.pdf) |                                     **Detoxification**&**Inhibition Control**&**Toxicity Reduction**                                     |
| 24.05 |                                                                                        GSAI POSTECH                                                                                        |      NAACL2024(findings)       |                                       [Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents](https://arxiv.org/abs/2405.12900)                                       |                                   **Adversarial Training**&**Toxicity Reduction**&**Dialogue Systems**                                   |
| 24.06 |                                                                                      Brown University                                                                                      |             arxiv              |                                                                     [Preference Tuning For Toxicity Mitigation Generalizes Across Languages](https://arxiv.org/abs/2406.16235)                                                                     |                              **Toxicity Mitigation**&**Cross-Lingual Generalization**&**Preference Tuning**                              |
| 24.07 |                                                                       Huazhong University of Science and Technology                                                                        |             arxiv              |                                                                                     [On the (In)Security of LLM App Stores](https://arxiv.org/abs/2407.08422)                                                                                      |                                               **LLM App Stores**&**Security**&**Privacy**                                                |
| 24.07 |                                                                                    Tsinghua University                                                                                     |             arxiv              |                                                                     [Model Surgery: Modulating LLM‚Äôs Behavior Via Simple Parameter Editing](https://arxiv.org/abs/2407.08770)                                                                      |                                                 **Parameter Editing**&**Detoxification**                                                 |
| 24.07 |                                                                                    Stanford University                                                                                     |             arxiv              |                                                      [ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts](https://arxiv.org/abs/2407.09447)                                                      |                                **Red-Teaming**&**Toxic Prompt Identification**&**Reinforcement Learning**                                |
| 24.07 |                                                                                  University of Rochester                                                                                   |             arxiv              |                                                       [Evolver: Chain-of-Evolution Prompting to Boost Large Multimodal Models for Hateful Meme Detection](https://arxiv.org/abs/2407.21004)                                                        |                                   **Large Multimodal Models**&**Hateful Meme Detection**&**Prompting**                                   |
| 24.08 |                                                                                    University of Ottawa                                                                                    |             arxiv              |                                                  [HateSieve: A Contrastive Learning Framework for Detecting and Segmenting Hateful Content in Multimodal Memes](https://arxiv.org/abs/2408.05794)                                                  |                               **Hateful Content Detection**&**Contrastive Learning**&**Multimodal Memes**                                |
| 24.08 |                                                                              National University of Singapore                                                                              |          eCrime 2024           |                                                               [Multimodal Large Language Models for Phishing Webpage Detection and Identification](https://arxiv.org/abs/2408.05941)                                                               |                                   **Phishing Detection**&**Multimodal LLMs**&**Brand Identification**                                    |
| 24.08 |                                                                              Nanyang Technological University                                                                              |            ASE 2024            |                                                                         [Efficient Detection of Toxic Prompts in Large Language Models](https://arxiv.org/abs/2408.11727)                                                                          |                                                 **Toxic Prompts**&**Jailbreak Attacks**                                                  |
| 24.10 |                                                                                   University of A Coru√±a                                                                                   |             arxiv              |                                                                       [Decoding Hate: Exploring Language Models' Reactions to Hate Speech](https://arxiv.org/abs/2410.00775)                                                                       |                                                **Hate Speech**&**Mitigation Strategies**                                                 |
| 24.10 |                                                                              Dalian University of Technology                                                                               |             arxiv              |                                                                            [Towards Comprehensive Detection of Chinese Harmful Memes](https://arxiv.org/abs/2410.02378)                                                                            |                                   **Chinese Harmful Memes**&**Multimodal Detection**&**Meme Toxicity**                                   |
| 24.10 |                                                                                     Cornell University                                                                                     |             arxiv              |                                                                     [How Toxicity Classifiers and Large Language Models Respond to Ableism](https://arxiv.org/abs/2410.03448)                                                                      |                                                   **Toxicity Classifiers**&**Ableism**                                                   |
| 24.10 |                                                                                     IBM Research, MIT                                                                                      |             arxiv              |                                                                              [Large Language Models Can Be Strong Self-Detoxifiers](https://arxiv.org/abs/2410.03818)                                                                              |                                              **Toxicity Reduction**&**Self-Detoxification**                                              |
| 24.10 |                                                                  University of California, Los Angeles, Amazon.com, Inc.                                                                   |      EMNLP 2024 Findings       |                                                           [Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification](https://arxiv.org/abs/2410.05559)                                                           |                                                 **Attribute Control**&**Detoxification**                                                 |
| 24.11 |                                                                                         Meta FAIR                                                                                          |             arXiv              |                                                                         [On the Role of Speech Data in Reducing Toxicity Detection Bias](https://arxiv.org/abs/2411.08135)                                                                         |                                  **Speech Toxicity Detection**&**Bias Reduction**&**Multimodal Models**                                  |
| 24.11 |                                                                           University of California, Los Angeles                                                                            |             arxiv              |                                                                [Leveraging Large Language Models and Topic Modeling for Toxicity Classification](https://arxiv.org/abs/2411.17876)                                                                 |                                     **Toxicity Classification**&**BERTweet**&**Bias in Classifiers**                                     |
| 24.12 |                                                                                      Wuhan University                                                                                      |             arxiv              |                                                                       [Toxicity Detection Towards Adaptability to Changing Perturbations](https://arxiv.org/abs/2412.15267)                                                                        |                                 **Toxicity Detection**&**Continual Learning**&**Perturbation Patterns**                                  |
| 25.01 |                                                                                    Amazon Web Services                                                                                     |          NeurIPS 2024          |                                                                                [Risk-Averse Fine-tuning of Large Language Models](https://arxiv.org/abs/2501.06911)                                                                                |                              **Risk-Averse Fine-tuning**&**Reinforcement Learning**&**Toxicity Mitigation**                              |
| 25.01 |                                                                                  Georgia State University                                                                                  |             arxiv              |                                                        [Playing Devil's Advocate: Unmasking Toxicity and Vulnerabilities in Large Vision-Language Models](https://arxiv.org/abs/2501.09039)                                                        |                                 **LVLMs Vulnerabilities**&**Toxicity Analysis**&**Adversarial Prompts**                                  |
| 25.01 |                                                                       University of Science and Technology of China                                                                        |             arxiv              |                                                            [Polarized Patterns of Language Toxicity and Sentiment of Debunking Posts on Social Media](https://arxiv.org/abs/2501.06274)                                                            |                                **Social Media Analysis**&**Language Toxicity**&**Political Polarization**                                |
| 25.01 |                                                                                   Politecnico di Milano                                                                                    |             arxiv              |                                                                 [How Toxic Can You Get? Search-Based Toxicity Testing for Large Language Models](https://arxiv.org/abs/2501.01741)                                                                 |                                 **Automated Testing**&**Evolutionary Algorithms**&**Toxicity Detection**                                 |
| 25.01 |                                                                              University of California, Davis                                                                               |             arxiv              |                                         [Towards Safer Social Media Platforms: Scalable and Performant Few-Shot Harmful Content Moderation Using Large Language Models](https://arxiv.org/abs/2501.13976)                                          |                                            **Social Media Moderation**&**Few-Shot Learning**                                             |
| 25.02 |                                                                                   Iowa State University                                                                                    |             arxiv              |                                                       [Evaluation of Hate Speech Detection using Large Language Models and Geographical Contextualization](https://arxiv.org/abs/2502.19612)                                                       |                                  **Hate Speech Detection**&**Geographical Context**&**LLM Robustness**                                   |
| 25.03 |                                                                                   University of Warwick                                                                                    |           NAACL 2025           |                                                  [SafeSpeech: A Comprehensive and Interactive Tool for Analysing Sexist and Abusive Language in Conversations](https://arxiv.org/abs/2503.06534)                                                   |                               **Toxic Speech Detection**&**Conversation Analysis**&**LLM Explainability**                                |
| 25.03 |                                                 Aston University, Jamhuriya University, Somali National University, University of Djibouti                                                 |             arxiv              |                                              [Detection of Somali-written Fake News and Toxic Messages on the Social Media Using Transformer-based Language Models](https://arxiv.org/abs/2503.18117)                                              |                                 **Somali NLP**&**Fake News Detection**&**Toxic Content Classification**                                  |
| 25.03 |                                                                                     Beihang University                                                                                     |             arxiv              |                                             [Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection](https://arxiv.org/abs/2503.21127)                                             |                            **Fake News Detection**&**LLM-SLM Collaboration**&**Retrieval-Augmented Learning**                            |
| 25.04 |                                                                                The University of Queensland                                                                                |             arxiv              |                                                                         [LLM-based Semantic Augmentation for Harmful Content Detection](https://arxiv.org/abs/2504.15548)                                                                          |                         **Semantic Augmentation**&**Harmful Content Detection**&**Social Media Classification**                          |
| 25.04 |                                                                                   Guangxi Police College                                                                                   |             arxiv              |                                                                        [Few-Shot Hate Speech Detection Based on the MindSpore Framework](https://arxiv.org/abs/2504.15987)                                                                         |                                 **Few-shot Learning**&**Hate Speech Detection**&**Prompt-based Models**                                  |
| 25.05 |                                                                                   University of Arkansas                                                                                   |             arxiv              |                                                            [Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models](https://arxiv.org/abs/2505.00150)                                                            |                         **Hateful Meme Detection**&**Vision-Language Models**&**Multimodal Content Mitigation**                          |
| 25.05 |                                                                                         Microsoft                                                                                          |             arxiv              |                                                  [Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs](https://arxiv.org/abs/2505.02009)                                                  |                                      **Data Filtering**&**Toxicity Detection**&**LLM Pretraining**                                       |
| 25.05 |                                                                                         TU Munich                                                                                          |             arxiv              |                                                       [Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study](https://arxiv.org/abs/2505.06149v1)                                                       |                                 **Hate Speech Detection**&**Multilingual LLMs**&**Prompting Strategies**                                 |
| 25.05 |                                                                          University of Illinois Urbana-Champaign                                                                           |             arxiv              |                                                                     [Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders](https://arxiv.org/abs/2505.14536)                                                                      |                                      **Detoxification**&**Sparse Autoencoders**&**Causal Steering**                                      |
| 25.05 |                                                                                    Universit√§t Hamburg                                                                                     |             arxiv              |                                                                 [Chinese Toxic Language Mitigation via Sentiment Polarity Consistent Rewrites](https://arxiv.org/abs/2505.15297v1)                                                                 |                                        **Detoxification**&**Sentiment Polarity**&**Chinese LLMs**                                        |
| 25.05 |                                                                               Shanghai Jiao Tong University                                                                                |       ACL 2025 Findings        |                                                        [Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings](https://arxiv.org/abs/2505.24341v1)                                                         |                                **Toxic Chinese Detection**&**Multimodal Perturbation**&**LLM Robustness**                                |
| 25.06 |                                                                                  University of Washington                                                                                  |             arxiv              |                                                         [Detoxification of Large Language Models through Output-layer Fusion with a Calibration Model](https://arxiv.org/abs/2506.01266v1)                                                         |                                   **LLM Detoxification**&**Calibration Model**&**Output-layer Fusion**                                   |
| 25.06 |                                                                                         TU Dresden                                                                                         |             arxiv              |                                                               [LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech Detoxification](https://arxiv.org/abs/2506.01484v1)                                                                |                                  **Hate Speech Detoxification**&**LLM Annotation**&**Parallel Dataset**                                  |
| 25.06 |                                                                                   Penn State University                                                                                    |             arxiv              |                                                                     [Something Just Like TRuST : Toxicity Recognition of Span and Target](https://arxiv.org/abs/2506.02326v1)                                                                      |                                 **Toxicity Detection**&**Target Social Group**&**Toxic Span Extraction**                                 |
| 25.06 |                                                                            Instituto Politecnico Nacional (IPN)                                                                            |             arxiv              |                                                [Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models](https://arxiv.org/abs/2506.08147)                                                |         **Translation-Based Approach**&**Hate Speech Detection**&**Social Media**&**Multilingual NLP**&**Large Language Model**          |
| 25.06 |                                                                  International Balkan University, University of Belgrade                                                                   |             arxiv              |                                                             [Large Language Models for Toxic Language Detection in Low-Resource Balkan Languages](https://arxiv.org/abs/2506.09992v1)                                                              |              **Toxic Language**&**Large Language Models**&**Low-Resource Language**&**Context Augmentation**&**Balkan NLP**              |
| 25.06 |                                                                            Indian Institute of Technology Delhi                                                                            |             arxiv              |                                                            [Rethinking Hate Speech Detection on Social Media: Can LLMs Replace Traditional Models?](https://arxiv.org/abs/2506.12744v1)                                                            | **Hate Speech Detection**&**Code-Mixed Language**&**Multilingual NLP**&**Large Language Models**&**IndoHateMix Dataset**&**Fine-Tuning** |
| 25.06 |                                                                                      Korea University                                                                                      |             arxiv              |                                                       [K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean](https://arxiv.org/abs/2506.13513v1)                                                       |            **Detoxification**&**Implicit Offensiveness**&**Paired Dataset**&**Retrieval-Augmented Generation**&**Korean NLP**            |
| 25.06 |                                                                                   Maastricht University                                                                                    |         ACL 2025 WOAH          |                                                                          [Towards Fairness Assessment of Dutch Hate Speech Detection](https://arxiv.org/abs/2506.12502v1)                                                                          |                      **Fairness**&**Hate Speech Detection**&**Dutch NLP**&**Counterfactual Generation**&**BERTje**                       |
| 25.06 |                                                                                   University of Toronto                                                                                    |             arxiv              |                                                                                            Human-Aligned Faithfulness in Toxicity Explanations of LLMs                                                                                             |                                          LLM Toxicity&Explainability&Human-Aligned Faithfulness                                          |
| 25.06 |                                                                                  Arizona State University                                                                                  |             arxiv              |                                                                     [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443v1)                                                                     |                                        **Fraud Detection**&**Concept Drift**&**Domain Knowledge**                                        |
| 25.07 |                                                           East China Normal University, Shanghai EastWonder Info-tech Co., Ltd.                                                            |             arxiv              |                                                             [Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization](https://arxiv.org/abs/2507.01050v1)                                                             |                                     **Detoxification**&**Semantic Preservation**&**Generalization**                                      |
| 25.07 |                                                                           University of California, Los Angeles                                                                            |             arxiv              |                                                                        [ModelCitizens: Representing Community Voices in Online Safety](https://arxiv.org/abs/2507.05455v2)                                                                         |                                       **Toxicity Detection**&**Community Annotation**&**Context**                                        |
| 25.07 |                                                                                       Virginia Tech                                                                                        |             arxiv              |                                                           [TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data](https://arxiv.org/abs/2507.05660v1)                                                           |                                         **Toxicity Mitigation**&**LLM Fine-tuning**&**Defense**                                          |
| 25.07 |                                                                       Huazhong University of Science and Technology                                                                        |             arxiv              |                                                      [Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation](https://arxiv.org/abs/2507.08020)                                                      |                                      **Large Language Model**&**Embedding Poisoning**&**Toxicity**                                       |
| 25.08 |                                                                                            EPFL                                                                                            |            MM 2025             |                                                        [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750v1)                                                        |                               **Implicit Hate Speech**&**LLM Embeddings**&**Cross-Dataset Generalization**                               |
| 25.09 |                                                                            The University of Western Australia                                                                             |             arxiv              |                            [Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech](https://arxiv.org/abs/2509.00673v1)                             |                                   **Hate Speech Detection**&**Safety Alignment**&**Ideological Bias**                                    |
| 25.09 |                                                                           Universidade de Santiago de Compostela                                                                           |              AAAI              |                                       [Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning](https://arxiv.org/abs/2509.07768v1)                                       |                            **Hyperpartisan Detection**&**Fake News**&**Fine-Tuning vs. In-Context Learning**                             |
| 25.09 |                                                                   Tsinghua University, National University of Singapore                                                                    |             arxiv              |                                                                   [When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs' Toxicity](https://arxiv.org/abs/2509.11141)                                                                    |                                      **Emoji-induced Toxicity**&**LLM Safety**&**Interpretability**                                      |
| 25.09 |                                                                                   University of Maryland                                                                                   |             arxiv              |                                          [SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models](https://arxiv.org/abs/2509.15174)                                          |                                **Toxicity Detection**&**Self-Augmenting LLMs**&**Explainable Moderation**                                |
| 25.09 |                                                                                 IIIT Delhi & IIIT Dharwad                                                                                  |          NeurIPS 2025          |                                                           [Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation](https://arxiv.org/abs/2509.16660)                                                           |                                   **Toxicity Mitigation**&**Interpretability**&**Eigen-Decomposition**                                   |
| 25.09 |                                  IIT Gandhinagar, MIT Media Lab, Carnegie Mellon University, Stanford University, University of South Carolina, IIT Patna                                  |             arxiv              |                                                            [DeHate: A Stable Diffusion-based Multimodal Approach to Mitigate Hate Speech in Images](https://arxiv.org/abs/2509.21787v1)                                                            |                                  **Hate Speech Detection**&**Stable Diffusion**&**Multimodal Dataset**                                   |
| 25.10 |                                                    University of Toronto, QCRI, Daffodil International University, Macquarie University                                                    |             arxiv              |                                                                [LLM-Based Multi-Task Bangla Hate Speech Detection: Type, Severity, and Target](https://arxiv.org/abs/2510.01995v1)                                                                 |                     **BanglaMultiHate Dataset**&**Hate Speech Detection**&**Low-Resource NLP**&**LoRA Fine-Tuning**                      |
| 25.10 |                                                              Universidade da Coru√±a & Universidade de Santiago de Compostela                                                               |             arxiv              |                                                   [Bridging Gaps in Hate Speech Detection: Meta-Collections and Benchmarks for Low-Resource Iberian Languages](https://arxiv.org/abs/2510.11167)                                                   |                                  **Hate Speech**&**Low-Resource Languages**&**Cross-Lingual Benchmark**                                  |
| 25.10 |                                                                            Universit√© C√¥te d‚ÄôAzur, CNRS, Inria                                                                             |             arxiv              |                                                                 [Beating Harmful Stereotypes Through Facts: RAG-based Counter-speech Generation](https://arxiv.org/abs/2510.12316)                                                                 |                                **Counter-Speech Generation**&**RAG Framework**&**Hate Speech Mitigation**                                |
| 25.10 |                                                                                    Syracuse University                                                                                     |             arxiv              |                                                            [Seeing Hate Differently: Hate Subspace Modeling for Culture-Aware Hate Speech Detection](https://arxiv.org/abs/2510.13837)                                                             |                                 **Hate Speech Detection**&**Cultural Bias**&**Representation Learning**                                  |
| 25.10 |                                                              Central China Normal University & Wuhan University of Technology                                                              |             EMNLP              |                                                                    [DSCD: Large Language Model Detoxification with Self-Constrained Decoding](https://arxiv.org/abs/2510.13183)                                                                    |                              **LLM Detoxification**&**Self-Constrained Decoding**&**Toxicity Suppression**                               |
| 25.10 |                                                    Southeast University, RIKEN, Qilu University of Technology, The University of Tokyo                                                     |             arxiv              |                                                               [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)                                                               |                                   **Toxicity Detection**&**Multi-Label Learning**&**Pseudo-Labeling**                                    |
| 25.10 |                                                                        University of Rajshahi, Marshall University                                                                         |        IEEE COMPAS 2025        |                                           [Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection](https://arxiv.org/abs/2510.16985)                                            |                         **Parameter-Efficient Fine-Tuning**&**Low-Resource Languages**&**Hate Speech Detection**                         |
| 25.10 |                                                                              MBZUAI, University of Edinburgh                                                                               |             arxiv              |                                                              [Online Learning Defense against Iterative Jailbreak Attacks via Prompt Optimization](https://arxiv.org/abs/2510.17006)                                                               |                                    **Jailbreak Defense**&**Online Learning**&**Prompt Optimization**                                     |
| 25.10 |                                                                         Metropolia University of Applied Sciences                                                                          |             arxiv              |                                               [Efficient Toxicity Detection in Gaming Chats: A Comparative Study of Embeddings, Fine-Tuned Transformers and LLMs](https://arxiv.org/abs/2510.17924)                                                |                                 **Toxicity Detection**&**Content Moderation**&**Large Language Models**                                  |
| 25.10 |                                                                 IIT Madras / University of Maryland / Princeton University                                                                 |             arxiv              |                                                           [Engagement Undermines Safety: How Stereotypes and Toxicity Shape Humor in Language Models](https://arxiv.org/abs/2510.18454)                                                            |                                           **Humor Generation**&**AI Safety**&**Toxicity Bias**                                           |
| 25.10 | University of Pittsburgh | arxiv | [Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing](https://arxiv.org/abs/2510.20727) | **Clinical NLP**&**Adverse Drug Event Extraction**&**LLM in Healthcare** |
| 25.11 | Dublin City University, University of Isfahan | arxiv | [SynBullying: A Multi-LLM Synthetic Conversational Dataset for Cyberbullying Detection](https://arxiv.org/abs/2511.11599) | **Cyberbullying Detection**&**Synthetic Dataset**&**Large Language Models** |
| 25.11 | Rochester Institute of Technology | arxiv | [ToxSearch: Evolving Prompts for Toxicity Search in Large Language Models](https://arxiv.org/abs/2511.12487) | **Toxicity Search**&**Evolutionary Prompt Optimization**&**Adversarial Prompt Attacks** |
| 25.12 | Dalian University of Technology | arxiv | [Prompt-Driven Large Language Model Merge for Fine-Grained Chinese Hate Speech Detection](https://arxiv.org/abs/2512.09563) | **Chinese Hate Speech Detection**&**Prompt Engineering**&**LLM Merging** |
| 25.12 | Graduate School of Information Science and Technology, The University of Tokyo | arxiv | [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052) | **MultimodalSafety**&**NeuronControl**&**Detoxification** |
| 25.12 | Fudan University | arxiv | [Prefix Probing: Lightweight Harmful Content Detection for Large Language Models](https://arxiv.org/abs/2512.16650) | **ContentDetection**&**PrefixCaching**&**LLMSafety** |
| 26.01 | University of South Carolina | arxiv | [Boosting Accuracy and Interpretability in Multilingual Hate Speech Detection Through Layer Freezing and Explainable AI](https://arxiv.org/abs/2601.02697) | **Hate Speech Detection**&**Explainable AI**&**Multilingual NLP** |
| 26.01 | Freie Universit√§t Berlin | arxiv | [ToxiGAN: Toxic Data Augmentation via LLM-Guided Directional Adversarial Generation](https://arxiv.org/abs/2601.03121) | **Toxicity Augmentation**&**Adversarial Generation**&**LLM Guidance** |


## üíªPresentations & Talks


## üìñTutorials & Workshops

| Date  |          Type          |       Title        |                                          URL                                          |
|:-----:|:----------------------:|:------------------:|:-------------------------------------------------------------------------------------:|
| 22.02 | Toxicity Detection API |  Perspective API   | [link](https://www.perspectiveapi.com/)<br/>[paper](https://arxiv.org/abs/2202.11176) |
| 23.10 |       Tutorials        | Awesome-LLM-Safety |                 [link](https://github.com/ydyjya/Awesome-LLM-Safety)                  |

## üì∞News & Articles

## üßë‚Äçüè´Scholars
