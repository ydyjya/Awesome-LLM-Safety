
Oral

1. <details>
          <summary>Students Parrot Their Teachers: Membership Inference on Model Distillation</summary>
          TL; DR: Model distillation is not resistant to strong membership inference attack.
   </details>

2. <details>
          <summary>Jailbroken: How Does LLM Safety Training Fail?</summary>
   </details>

Spotlight

1. <details>
          <summary>Honesty Is the Best Policy: Defining and Mitigating AI Deception</summary>
          TL; DR: We formally define deception in the causal game framework and mitigate deception in reinforcement learning agents and language models.
   </details>

2.  <details>
          <summary>ProPILE: Probing Privacy Leakage in Large Language Models</summary>
   </details>
